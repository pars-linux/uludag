=== added file 'apport/crashdb_impl/bugzilla.py'
--- apport/crashdb_impl/bugzilla.py	1970-01-01 00:00:00 +0000
+++ apport/crashdb_impl/bugzilla.py	2009-06-19 19:58:10 +0000
@@ -0,0 +1,926 @@
+# -*- coding: utf-8 -*-
+
+import apport.crashdb
+import atexit
+import gzip
+import os
+import re
+import tempfile
+
+from base64 import b64decode
+from bugz.bugzilla import Bugz
+from bugz.config import config
+from email.parser import Parser
+from StringIO import StringIO
+from urlparse import urljoin
+
+
+BUGZILLA_URL = 'http://localhost/bugzilla/'
+MYUSERNAME = 'asd@asd.com'
+MYPASSWORD = 'asd'
+
+# FIXME: importing from apport.crashdb_impl.launchpad creates a requirement
+#        of launchpadlib, which is not needed when using the Bugzilla backend
+#        perhaps the best choice here is creating a common_data module to be
+#        used by every crashdb.
+APPORT_FILES = ('Dependencies.txt', 'CoreDump.gz', 'ProcMaps.txt',
+        'Traceback.txt', 'Disassembly.txt', 'Registers.txt', 'Stacktrace.txt',
+        'ThreadStacktrace.txt', 'DpkgTerminalLog.txt', 'DpkgTerminalLog.gz')
+
+class Bug(object):
+    """
+    This class abstracts operations on the ElementTree returned by bugz for a
+    bug entry.
+    Some attributes as lazilly evaluated to avoid a performance hit every time
+    we instantiate a bug objetc.
+    """
+
+    def __init__(self, bug_id, node):
+        """
+        Constructor.
+
+        bug_id -- The bug ID as specified by Bugzilla
+        node -- The ElementTree object returned by bygz.get(id)
+        """
+        assert bug_id > 0, "The bug ID must be greater than zero"
+        assert node, "Can't instantiate Bug without an ElementTree parameter"
+        self.bug_id = bug_id
+        self._node = node
+        self.setup()
+
+
+    def setup(self):
+        """
+        Initializes basic data.
+        """
+        self._comments = None
+        self._attachments = None
+        self._keywords = None
+        self.title = self._node.find('//short_desc').text
+        self.create_date = self._node.find('//creation_ts').text
+        self.reporter = self._node.find('//reporter').text
+        self.status = self._node.find('//bug_status').text
+        try:
+            self.resolution = self._node.find('//resolution').text
+            if self.resolution == 'DUPLICATE':
+                self.dup_id = int(self._node.find('//dup_id').text)
+        except AttributeError:
+            # Use empty string instead of None so we can search for
+            # patterns inside bug.resolution easily
+            self.resolution = ''
+            self.dup_id = 0
+
+
+    @property
+    def description(self):
+        """
+        Returns the Bug's description by the commiter.
+        """
+        return self.comments[0]['text']
+
+
+    @property
+    def keywords(self):
+        """
+        A list of the keywords a bug has.
+        """
+        if self._keywords is not None:
+            return self._keywords
+
+        try:
+            keys = self._node.find('//keywords').text
+            self._keywords = keys.split(', ')
+        except AttributeError:
+            self._keywords = []
+        return self._keywords
+
+
+    @property
+    def comments(self):
+        """
+        A list of comments on the bug.
+        Each comment is represented as a dictionary with the following keys:
+            * author
+            * date
+            * text
+        """
+        if self._comments is not None:
+            return self._comments
+
+        self._comments = []
+        etree = self._node.findall('//long_desc')
+        for tree in etree:
+            comment = {
+                'author': tree.find('.//who').text,
+                'date': tree.find('.//bug_when').text,
+                'text': tree.find('.//thetext').text,
+            }
+            self._comments.append(comment)
+        return self._comments
+
+
+    @property
+    def attachments(self):
+        """
+        Returns a list of the bug's attachment.
+        Each attachment is represented as a dictionary with the following keys:
+            * id
+            * date
+            * description
+            * filename
+            * type
+        """
+        if self._attachments is not None:
+            return self._attachments
+
+        self._attachments = []
+        etree = self._node.findall('//attachment')
+        for tree in etree:
+            if tree.attrib['isobsolete'] == '1':
+                continue
+            attachment = {
+                'id': int(tree.find('.//attachid').text),
+                'date': tree.find('.//date').text,
+                'description': tree.find('.//desc').text,
+                'filename': tree.find('.//filename').text,
+                'type': tree.find('.//type').text,
+            }
+            self._attachments.append(attachment)
+        return self._attachments
+
+
+class CrashDatabase(apport.crashdb.CrashDatabase):
+    """
+    Bugzilla implementation of crash database interface.
+    """
+
+    def __init__(self, auth, bugpattern_baseurl, options):
+        """
+        Constructor.
+
+        auth_file -- authentication credentials
+        bugpattern_baseurl -- base url for searching bug patterns
+        options -- dictionary with settings from crashdb.conf
+        """
+        apport.crashdb.CrashDatabase.__init__(self, auth, bugpattern_baseurl,
+                                              options)
+        self.distro = options.get('distro')
+        self.options = options
+        self.auth = auth
+        self.arch_tag = 'need-%s-retrace' % apport.packaging.get_system_architecture()
+
+        self._bugzilla = None
+        self._baseurl = None
+
+
+    @property
+    def bugzilla(self):
+        """
+        Return Bugzilla instance.
+        TODO: check whether we should use cookies or not
+        """
+        if self._bugzilla is not None:
+            return self._bugzilla
+
+        self._baseurl = self.options.get('baseurl')
+        self._bugzilla = Bugz(self._baseurl, MYUSERNAME, MYPASSWORD)
+        #FIXME: login should be handled elsewhere
+        if not self._bugzilla:
+            print >> sys.stderr, 'Error acquiring Bugzilla instance'
+            sys.exit(1)
+        return self._bugzilla
+
+
+    def upload(self, report, progress_callback = None):
+        '''Upload given problem report return a handle for it.
+
+        This should happen noninteractively.
+
+        If the implementation supports it, and a function progress_callback is
+        passed, that is called repeatedly with two arguments: the number of
+        bytes already sent, and the total number of bytes to send. This can be
+        used to provide a proper upload progress indication on frontends.'''
+        data = {}
+
+        # PyBugz mandatory args
+        product = 'TestProduct'
+        component = 'TestComponent'
+        #product = 'FoodReplicator'
+        #component = 'SpiceDispenser'
+        title = report.get('Title', report.standard_title())
+        description = ''
+
+        # generating mime (from launchpad.py)#{{{
+        # set reprocessing tags
+        hdr = {}
+        hdr['Tags'] = 'apport-%s' % report['ProblemType'].lower()
+        a = report.get('PackageArchitecture')
+        if not a or a == 'all':
+            a = report.get('Architecture')
+        if a:
+            hdr['Tags'] += ' ' + a
+        if 'CoreDump' in report and a:
+            hdr['Tags'] += ' need-%s-retrace' % a
+        # set dup checking tag for Python crashes
+        elif report.has_key('Traceback'):
+            hdr['Tags'] += ' need-duplicate-check'
+
+        # write MIME/Multipart version into temporary file
+        mime = tempfile.NamedTemporaryFile()
+        report.write_mime(mime, extra_headers=hdr)
+        mime.flush()
+        mime.seek(0)
+        #TODO: decide whether to implement multipart upload#}}}
+        # Reding MIME data and uploading each file
+        message = Parser().parse(mime)
+        attachables = []
+        for item in message.walk():
+            filename = item.get_filename()
+            # If "Content-Disposition" is inline, filename will be None
+            if filename is not None:
+                data = b64decode(item.get_payload())
+                filetype = item.get_content_type()
+                attachable = (filename, filetype, data)
+                attachables.append(attachable)
+            else:
+                # Bug description is `inline`
+                try:
+                    description += b64decode(item.get_payload())
+                except:
+                    pass
+        mime.close()
+
+        # optional args
+        data = {
+            #'url': '',
+            #'assigned_to': '',
+            #'cc': '',
+            'keywords': hdr['Tags'],
+            'version': 'unspecified',
+            #'version': '1.0',
+            #'dependson': '',
+            #'blocked': '',
+            #'priority': 'P2',
+            #'severity': 'minor',
+        }
+
+        bug_id = self.bugzilla.post(product, component, title, description,
+                                    **data)
+        if bug_id == 0:
+            raise RuntimeError, "Error uploading bug!"
+
+        for filename, filetype, data in attachables:
+            tmp = tempfile.NamedTemporaryFile()
+            tmp.write(data)
+            tmp.flush()
+            tmp.seek(0)
+            result = self.bugzilla.attach(bug_id, filename, '', tmp.name,
+                                          filetype, filename)
+            if not result:
+                raise RuntimeError, "Error uploading attachment"
+            tmp.close()
+
+        return bug_id
+
+
+    def get_comment_url(self, report, handle):
+        '''Return an URL that should be opened after report has been uploaded
+        and upload() returned handle.
+
+        Should return None if no URL should be opened (anonymous filing without
+        user comments); in that case this function should do whichever
+        interactive steps it wants to perform.'''
+
+        url = '%s?id=%s' % (urljoin(self._baseurl, config.urls['show']),
+                            handle)
+        return url
+
+
+    def download(self, bug_id):
+        '''Download the problem report from given ID and return a Report.'''
+
+        report = apport.Report()
+        bug_etree = self.bugzilla.get(bug_id)
+        bug = Bug(bug_id, bug_etree)
+
+        # from launchpad crashdb
+        # parse out fields from summary
+        m = re.search(r'(ProblemType:.*)$', bug.description, re.S)
+        if not m:
+            m = re.search(r'^--- \r?$[\r\n]*(.*)', bug.description, re.M | re.S)
+        assert m, 'bug description must contain standard apport format data'
+
+        description = m.group(1).encode('UTF-8').replace('\xc2\xa0', ' ')
+
+        if '\r\n\r\n' in description:
+            # this often happens, remove all empty lines between top and
+            # 'Uname'
+            if 'Uname:' in description:
+                # this will take care of bugs like LP #315728 where stuff
+                # is added after the apport data
+                (part1, part2) = description.split('Uname:', 1)
+                description = part1.replace('\r\n\r\n', '\r\n') + 'Uname:' \
+                    + part2.split('\r\n\r\n', 1)[0]
+            else:
+                description = description.replace('\r\n\r\n', '\r\n')
+
+        report.load(StringIO(description))
+
+        when = bug.create_date
+        if 'Date' not in report:
+            report['Date'] = when
+
+        if 'ProblemType' not in report:
+            if 'apport-bug' in bug.keywords:
+                report['ProblemType'] = 'Bug'
+            elif 'apport-crash' in bug.keywords:
+                report['ProblemType'] = 'Crash'
+            elif 'apport-kernelcrash' in bug.keywords:
+                report['ProblemType'] = 'KernelCrash'
+            elif 'apport-package' in bug.keywords:
+                report['ProblemType'] = 'Package'
+            else:
+                raise ValueError, 'cannot determine ProblemType from tags: '\
+                        + str(bug.keywords)
+
+        for attachment in bug.attachments:
+            if attachment['filename'] in APPORT_FILES:
+                key, ext = os.path.splitext(attachment['filename'])
+                att = self.bugzilla.attachment(attachment['id'])
+                if att is None:
+                    raise RuntimeError, 'Error downloading attachment'
+                if ext == '.txt':
+                    report[key] = att['fd'].read()
+                elif ext == '.gz':
+                    #report[key] = gzip.GzipFile(fileobj=att['fd']).read()
+                    report[key] = att['fd'].read()
+                else:
+                    raise RuntimeError, 'Unable to read %s file' % ext
+        return report
+
+
+    def update(self, bug_id, report, comment):
+        '''Update the given report ID with the retraced results from the report
+        (Stacktrace, ThreadStacktrace, StacktraceTop; also Disassembly if
+        desired) and an optional comment.'''
+
+        bug_etree = self.bugzilla.get(bug_id)
+        bug = Bug(bug_id, bug_etree)
+
+        comment += '\n\nStacktraceTop:' + report['StacktraceTop'].decode('utf-8',
+            'replace').encode('utf-8')
+
+        # FIXME: too much duplicated code. Itter over a list, perhaps?
+        if report['Stacktrace']: # don't attach empty files
+            tmp = tempfile.NamedTemporaryFile()
+            s = report['Stacktrace'].decode('ascii', 'replace').encode('ascii', 'replace')
+            tmp.write(s)
+            tmp.flush()
+            tmp.seek(0)
+            self.bugzilla.attach(bug_id, 'Stacktrace.txt (retraced)',
+                                 comment, tmp.name,
+                                 filename_override='Stacktrace.txt')
+            tmp.close()
+
+        if report['ThreadStacktrace']:
+            tmp = tempfile.NamedTemporaryFile()
+            s = report['ThreadStacktrace'].decode('ascii', 'replace').encode('ascii', 'replace')
+            tmp.write(s)
+            tmp.flush()
+            tmp.seek(0)
+            self.bugzilla.attach(bug_id, 'ThreadStacktrace.txt (retraced)',
+                                 '', tmp.name,
+                                 filename_override='ThreadStacktrace.txt')
+            tmp.close()
+
+        if report.has_key('StacktraceSource') and report['StacktraceSource']:
+            tmp = tempfile.NamedTemporaryFile()
+            s = report['StacktraceSource'].decode('ascii', 'replace').encode('ascii', 'replace')
+            tmp.write(s)
+            tmp.flush()
+            tmp.seek(0)
+            self.bugzilla.attach(bug_id, 'StacktraceSource.txt (retraced)',
+                                 '', tmp.name,
+                                 filename_override='StacktraceSource.txt')
+            tmp.close()
+
+        # ensure it's assigned to the right package
+        # TODO: implement-me
+        #if report.has_key('SourcePackage') and \
+        #        '+source' not in str(bug.bug_tasks[0].target):
+        #    try:
+        #        bug.bug_tasks[0].transitionToTarget(target=
+        #                self.lp_distro.getSourcePackage(name=report['SourcePackage']))
+        #    except HTTPError:
+        #        pass # LP#342355 workaround
+
+        # remove core dump if stack trace is usable
+        if report.has_useful_stacktrace():
+            for a in bug.attachments:
+                if a['filename'] == 'CoreDump.gz':
+                    # Setting the attachment as obsolete is the closest to
+                    # deleting it we can get with bugzilla
+                    params = {
+                        'isobsolete': 1,
+                    }
+                    self.bugzilla.modify_attachment(a['id'], bug_id,**params)
+
+
+    def get_distro_release(self, bug_id):
+        '''Get 'DistroRelease: <release>' from the given report ID and return
+        it.'''
+
+        bug_etree = self.bugzilla.get(bug_id)
+        bug = Bug(bug_id, bug_etree)
+        m = re.search('DistroRelease: ([-a-zA-Z0-9.+/ ]+)', bug.description)
+        if m:
+            return m.group(1)
+        raise ValueError, 'URL does not contain DistroRelease: field'
+
+
+    def get_unretraced(self):
+        '''Return an ID set of all crashes which have not been retraced yet and
+        which happened on the current host architecture.'''
+
+        bugs = self.bugzilla.search('', keywords=self.arch_tag)
+        if bugs is None:
+            return []
+        return set([int(bug['bugid']) for bug in bugs])
+
+
+    def get_dup_unchecked(self):
+        '''Return an ID set of all crashes which have not been checked for
+        being a duplicate.
+
+        This is mainly useful for crashes of scripting languages such as
+        Python, since they do not need to be retraced. It should not return
+        bugs that are covered by get_unretraced().'''
+
+        bugs = self.bugzilla.search('', keywords='need-duplicate-check')
+        if bugs is None:
+            return []
+        return set([int(bug['bugid']) for bug in bugs])
+
+
+    def get_unfixed(self):
+        '''Return an ID set of all crashes which are not yet fixed.
+
+        The list must not contain bugs which were rejected or duplicate.
+
+        This function should make sure that the returned list is correct. If
+        there are any errors with connecting to the crash database, it should
+        raise an exception (preferably IOError).'''
+
+        bugs = self.bugzilla.search('', keywords='apport-crash')
+        if bugs is None:
+            return []
+        return set([int(bug['bugid']) for bug in bugs])
+
+
+    def get_fixed_version(self, bug_id):
+        '''Return the package version that fixes a given crash.
+
+        Return None if the crash is not yet fixed, or an empty string if the
+        crash is fixed, but it cannot be determined by which version. Return
+        'invalid' if the crash report got invalidated, such as closed a
+        duplicate or rejected.
+
+        This function should make sure that the returned result is correct. If
+        there are any errors with connecting to the crash database, it should
+        raise an exception (preferably IOError).'''
+
+        bug_etree = self.bugzilla.get(bug_id)
+        bug = Bug(bug_id, bug_etree)
+        invalid_resolutions = ['DUPLICATE', 'WONTFIX', 'INVALID']
+        if bug.resolution == 'FIXED':
+            #TODO: check if there's a way to know the solved version
+            return ''
+        elif bug.resolution in invalid_resolutions:
+            return 'invalid'
+        else:
+            return None
+
+
+    def duplicate_of(self, bug_id):
+        '''Return master ID for a duplicate bug.
+
+        If the bug is not a duplicate, return None.
+        '''
+        bug_etree = self.bugzilla.get(bug_id)
+        bug = Bug(bug_id, bug_etree)
+        if bug.dup_id == 0:
+            return None
+        else:
+            return bug.dup_id
+
+
+    def close_duplicate(self, bug_id, master):
+        '''Mark a crash id as duplicate of given master ID.
+
+        If master is None, id gets un-duplicated.
+        '''
+        if master is not None:
+            self.bugzilla.modify(bug_id, duplicate=master,
+                                 resolution='DUPLICATE')
+        else:
+            self.bugzilla.modify(bug_id, status='REOPENED')
+
+
+    def mark_regression(self, bug_id, master):
+        '''Mark a crash id as reintroducing an earlier crash which is
+        already marked as fixed (having ID 'master').'''
+
+        regression_keyword = 'regression-retracer'
+        bug_etree = self.bugzilla.get(bug_id)
+        bug = Bug(bug_id, bug_etree)
+        kws = bug.keywords
+        if regression_keyword not in kws:
+            kws.append(regression_keyword)
+            self.bugzilla.modify(bug_id, keywords=' '.join(kws))
+
+
+    def mark_retraced(self, bug_id):
+        '''Mark crash id as retraced.'''
+
+        bug_etree = self.bugzilla.get(bug_id)
+        bug = Bug(bug_id, bug_etree)
+        kws = bug.keywords
+        if self.arch_tag in kws:
+            kws.remove(self.arch_tag)
+            args = {
+                'keywords': ' '.join(kws),
+            }
+            self.bugzilla.modify(bug_id, **args)
+
+
+    def mark_retrace_failed(self, bug_id, invalid_msg=None):
+        '''Mark crash id as 'failed to retrace'.
+
+        If invalid_msg is given, the bug should be closed as invalid with given
+        message, otherwise just marked as a failed retrace.
+
+        This can be a no-op if you are not interested in this.'''
+
+        if invalid_msg is not None:
+            self.bugzilla.modify(bug_id, status='RESOLVED',
+                                 resolution='INVALID', comment=invalid_msg)
+        else:
+            bug_etree = self.bugzilla.get(bug_id)
+            bug = Bug(bug_id, bug_etree)
+            kws = bug.keywords
+            kws.append('apport-failed-retrace')
+            new_kws = ' '.join(kws)
+            self.bugzilla.modify(bug_id, keywords=new_kws)
+
+
+    def _mark_dup_checked(self, bug_id, report):
+        '''Mark crash id as checked for being a duplicate
+
+        This is an internal method that should not be called from outside.'''
+
+        bug_etree = self.bugzilla.get(bug_id)
+        bug = Bug(bug_id, bug_etree)
+        kws = bug.keywords
+        try:
+            kws.remove('need-duplicate-check')
+            new_kws = ' '.join(kws)
+            self.bugzilla.modify(bug_id, keywords=new_kws)
+        except ValueError:
+            # This happens when the bug doesn't have the
+            # need-duplicate-check keyword
+            pass
+
+
+if __name__ == '__main__':
+    import unittest, urllib2, cookielib
+
+    crashdb = None
+    segv_report = None
+    python_report = None
+
+    class _Tests(unittest.TestCase):
+        # this assumes that a source package 'coreutils' exists and builds a
+        # binary package 'coreutils'
+        test_package = 'coreutils'
+        test_srcpackage = 'coreutils'
+        known_test_id = 12
+        known_test_id2 = 13
+
+        #
+        # Generic tests, should work for all CrashDB implementations
+        #
+
+        def setUp(self):
+            global crashdb
+            if not crashdb:
+                crashdb = self._get_instance()
+            self.crashdb = crashdb
+
+            # create a local reference report so that we can compare
+            # DistroRelease, Architecture, etc.
+            self.ref_report = apport.Report()
+            self.ref_report.add_os_info()
+            self.ref_report.add_user_info()
+
+        def _file_segv_report(self):
+            '''File a SEGV crash report.
+
+            Return crash ID.
+            '''
+            r = apport.report._ApportReportTest._generate_sigsegv_report()
+            r.add_package_info(self.test_package)
+            r.add_os_info()
+            r.add_gdb_info()
+            r.add_user_info()
+            self.assertEqual(r.standard_title(), 'crash crashed with SIGSEGV in f()')
+
+            handle = self.crashdb.upload(r)
+            self.assert_(handle)
+            url = self.crashdb.get_comment_url(r, handle)
+            self.assert_(url)
+            return handle
+
+
+        def test_1_report_segv(self):
+            '''upload() and get_comment_url() for SEGV crash
+
+            This needs to run first, since it sets segv_report.
+            '''
+            global segv_report
+            id = self._file_segv_report()
+            segv_report = id
+
+        def test_1_report_python(self):
+            '''upload() and get_comment_url() for Python crash
+
+            This needs to run early, since it sets python_report.
+            '''
+            r = apport.Report('Crash')
+            r['ExecutablePath'] = '/bin/foo'
+            r['Traceback'] = '''Traceback (most recent call last):
+  File "/bin/foo", line 67, in fuzz
+    print weird
+NameError: global name 'weird' is not defined'''
+            r.add_package_info(self.test_package)
+            r.add_os_info()
+            r.add_user_info()
+            self.assertEqual(r.standard_title(), 'foo crashed with NameError in fuzz()')
+
+            handle = self.crashdb.upload(r)
+            self.assert_(handle)
+            url = self.crashdb.get_comment_url(r, handle)
+            self.assert_(url)
+
+            global python_report
+            python_report = handle
+
+        def test_2_download(self):
+            '''download()'''
+
+            r = self.crashdb.download(segv_report)
+            self.assertEqual(r['ProblemType'], 'Crash')
+            self.assertEqual(r['DistroRelease'], self.ref_report['DistroRelease'])
+            self.assertEqual(r['Architecture'], self.ref_report['Architecture'])
+            self.assertEqual(r['Uname'], self.ref_report['Uname'])
+            self.assertEqual(r.get('NonfreeKernelModules'),
+                self.ref_report.get('NonfreeKernelModules'))
+            self.assertEqual(r.get('UserGroups'), self.ref_report.get('UserGroups'))
+
+            self.assertEqual(r['Signal'], '11')
+            self.assert_(r['ExecutablePath'].endswith('/crash'))
+            self.assertEqual(r['SourcePackage'], self.test_srcpackage)
+            self.assert_(r['Package'].startswith(self.test_package + ' '))
+            self.assert_('f (x=42)' in r['Stacktrace'])
+            self.assert_('f (x=42)' in r['StacktraceTop'])
+            self.assert_('f (x=42)' in r['ThreadStacktrace'])
+            self.assert_(len(r['CoreDump']) > 1000)
+            self.assert_('Dependencies' in r)
+            self.assert_('Disassembly' in r)
+            self.assert_('Registers' in r)
+
+        def test_3_update(self):
+            '''update()'''
+
+            r = self.crashdb.download(segv_report)
+            self.assert_('CoreDump' in r)
+            self.assert_('Dependencies' in r)
+            self.assert_('Disassembly' in r)
+            self.assert_('Registers' in r)
+            self.assert_('Stacktrace' in r)
+            self.assert_('ThreadStacktrace' in r)
+
+            # updating with an useless stack trace retains core dump
+            r['StacktraceTop'] = '?? ()'
+            r['Stacktrace'] = 'long\ntrace'
+            r['ThreadStacktrace'] = 'thread\neven longer\ntrace'
+            self.crashdb.update(segv_report, r, 'I can has a better retrace?')
+            r = self.crashdb.download(segv_report)
+            self.assert_('CoreDump' in r)
+            self.assert_('Dependencies' in r)
+            self.assert_('Disassembly' in r)
+            self.assert_('Registers' in r)
+            self.assert_('Stacktrace' in r) # TODO: ascertain that it's the updated one
+            self.assert_('ThreadStacktrace' in r)
+
+            # updating with an useful stack trace removes core dump
+            r['StacktraceTop'] = 'read () from /lib/libc.6.so\nfoo (i=1) from /usr/lib/libfoo.so'
+            r['Stacktrace'] = 'long\ntrace'
+            r['ThreadStacktrace'] = 'thread\neven longer\ntrace'
+            self.crashdb.update(segv_report, r, 'good retrace!')
+            r = self.crashdb.download(segv_report)
+            self.failIf('CoreDump' in r)
+            self.assert_('Dependencies' in r)
+            self.assert_('Disassembly' in r)
+            self.assert_('Registers' in r)
+            self.assert_('Stacktrace' in r)
+            self.assert_('ThreadStacktrace' in r)
+
+            # test various situations which caused crashes
+            r['Stacktrace'] = '' # empty file
+            r['ThreadStacktrace'] = '"]\xb6"\n' # not interpretable as UTF-8, LP #353805
+            self.crashdb.update(segv_report, r, 'tests')
+
+        def test_get_distro_release(self):
+            '''get_distro_release()'''
+
+            self.assertEqual(self.crashdb.get_distro_release(segv_report),
+                    self.ref_report['DistroRelease'])
+
+        def test_duplicates(self):
+            '''duplicate handling'''
+
+            # initially we have no dups
+            self.assertEqual(self.crashdb.duplicate_of(segv_report), None)
+            self.assertEqual(self.crashdb.get_fixed_version(segv_report), None)
+
+            # dupe our segv_report and check that it worked; then undupe it
+            self.crashdb.close_duplicate(segv_report, self.known_test_id)
+            self.assertEqual(self.crashdb.duplicate_of(segv_report), self.known_test_id)
+
+            # this should be a no-op
+            self.crashdb.close_duplicate(segv_report, self.known_test_id)
+            self.assertEqual(self.crashdb.duplicate_of(segv_report), self.known_test_id)
+
+            self.assertEqual(self.crashdb.get_fixed_version(segv_report), 'invalid')
+            self.crashdb.close_duplicate(segv_report, None)
+            self.assertEqual(self.crashdb.duplicate_of(segv_report), None)
+            self.assertEqual(self.crashdb.get_fixed_version(segv_report), None)
+
+            # this should have removed attachments; note that Stacktrace is
+            # short, and thus inline
+            #XXX: this won't happen in Bugzilla
+            #r = self.crashdb.download(segv_report)
+            #self.failIf('CoreDump' in r)
+            #self.failIf('Dependencies' in r)
+            #self.failIf('Disassembly' in r)
+            #self.failIf('Registers' in r)
+
+            # now try duplicating to a duplicate bug; this should automatically
+            # transition to the master bug
+            #XXX: this won't happen also
+            #TODO: check whether to implement this on close_duplicate() or not
+            #self.crashdb.close_duplicate(self.known_test_id,
+            #        self.known_test_id2)
+            #self.crashdb.close_duplicate(segv_report, self.known_test_id)
+            #self.assertEqual(self.crashdb.duplicate_of(segv_report),
+            #        self.known_test_id2)
+
+            self.crashdb.close_duplicate(self.known_test_id, None)
+            self.crashdb.close_duplicate(self.known_test_id2, None)
+            self.crashdb.close_duplicate(segv_report, None)
+
+            # this should be a no-op
+            self.crashdb.close_duplicate(self.known_test_id, None)
+            self.assertEqual(self.crashdb.duplicate_of(self.known_test_id), None)
+
+            self.crashdb.mark_regression(segv_report, self.known_test_id)
+            self._verify_marked_regression(segv_report)
+
+        def test_marking_segv(self):
+            '''processing status markings for signal crashes'''
+
+            # mark_retraced()
+            unretraced_before = self.crashdb.get_unretraced()
+            self.assert_(segv_report in unretraced_before)
+            self.failIf(python_report in unretraced_before)
+            self.crashdb.mark_retraced(segv_report)
+            unretraced_after = self.crashdb.get_unretraced()
+            self.failIf(segv_report in unretraced_after)
+            self.assertEqual(unretraced_before,
+                    unretraced_after.union(set([segv_report])))
+            self.assertEqual(self.crashdb.get_fixed_version(segv_report), None)
+
+            # mark_retrace_failed()
+            self._mark_needs_retrace(segv_report)
+            self.crashdb.mark_retraced(segv_report)
+            self.crashdb.mark_retrace_failed(segv_report)
+            unretraced_after = self.crashdb.get_unretraced()
+            self.failIf(segv_report in unretraced_after)
+            self.assertEqual(unretraced_before,
+                    unretraced_after.union(set([segv_report])))
+            self.assertEqual(self.crashdb.get_fixed_version(segv_report), None)
+
+            # mark_retrace_failed() of invalid bug
+            self._mark_needs_retrace(segv_report)
+            self.crashdb.mark_retraced(segv_report)
+            self.crashdb.mark_retrace_failed(segv_report, "I don't like you")
+            unretraced_after = self.crashdb.get_unretraced()
+            self.failIf(segv_report in unretraced_after)
+            self.assertEqual(unretraced_before,
+                    unretraced_after.union(set([segv_report])))
+            self.assertEqual(self.crashdb.get_fixed_version(segv_report),
+                    'invalid')
+
+        def test_marking_python(self):
+            '''processing status markings for interpreter crashes'''
+
+            unchecked_before = self.crashdb.get_dup_unchecked()
+            self.assert_(python_report in unchecked_before)
+            self.failIf(segv_report in unchecked_before)
+            self.crashdb._mark_dup_checked(python_report, self.ref_report)
+            unchecked_after = self.crashdb.get_dup_unchecked()
+            self.failIf(python_report in unchecked_after)
+            self.assertEqual(unchecked_before,
+                    unchecked_after.union(set([python_report])))
+            self.assertEqual(self.crashdb.get_fixed_version(python_report),
+                    None)
+
+        def test_update_invalid(self):
+            '''updating a invalid crash
+
+            This simulates a race condition where a crash being processed gets
+            invalidated by marking it as a duplicate.
+            '''
+            id = self._file_segv_report()
+
+            r = self.crashdb.download(id)
+
+            self.crashdb.close_duplicate(id, segv_report)
+
+            # updating with an useful stack trace removes core dump
+            r['StacktraceTop'] = 'read () from /lib/libc.6.so\nfoo (i=1) from /usr/lib/libfoo.so'
+            r['Stacktrace'] = 'long\ntrace'
+            r['ThreadStacktrace'] = 'thread\neven longer\ntrace'
+            self.crashdb.update(id, r, 'good retrace!')
+
+            r = self.crashdb.download(id)
+            self.failIf('CoreDump' in r)
+
+        def test_get_fixed_version(self):
+            '''get_fixed_version() for fixed bugs
+
+            Other cases are already checked in test_marking_segv() (invalid
+            bugs) and test_duplicates (duplicate bugs) for efficiency.
+            '''
+            self._mark_report_fixed(segv_report)
+            fixed_ver = self.crashdb.get_fixed_version(segv_report)
+            self.assertNotEqual(fixed_ver, None)
+            #FIXME: not yet implemented
+            #self.assert_(fixed_ver[0].isdigit())
+            self._mark_report_new(segv_report)
+            self.assertEqual(self.crashdb.get_fixed_version(segv_report), None)
+
+        # Bugzilla implementation
+        @classmethod
+        def _get_instance(klass):
+            return CrashDatabase(None,None,{'baseurl': BUGZILLA_URL})
+
+        def _mark_needs_retrace(self, id):
+            '''Mark a report ID as needing retrace.'''
+
+            bug = self.crashdb.bugzilla.get(id)
+            b = Bug(id, bug)
+            kws = b.keywords
+            if self.crashdb.arch_tag not in kws:
+                kws.append(self.crashdb.arch_tag)
+                self.crashdb.bugzilla.modify(id, keywords=' '.join(kws))
+
+        def _mark_needs_dupcheck(self, id):
+            '''Mark a report ID as needing duplicate check.'''
+
+            bug = self.crashdb.bugzilla.get(id)
+            b = Bug(id, bug)
+            kws = b.keywords
+            if 'need-duplicate-check' not in kws:
+                kws.append('need-duplicate-check')
+                self.crashdb.bugzilla.modify(id, keywords=' '.join(kws))
+
+        def _mark_report_fixed(self, id):
+            '''Close a report ID as "fixed".'''
+
+            self.crashdb.bugzilla.modify(id, status='RESOLVED',
+                                         resolution='FIXED')
+
+        def _mark_report_new(self, id):
+            '''Reopen a report ID as "new".'''
+
+            self.crashdb.bugzilla.modify(id, status='REOPENED')
+
+        def _verify_marked_regression(self, id):
+            '''Verify that report ID is marked as regression.'''
+
+            bug = self.crashdb.bugzilla.get(id)
+            b = Bug(id, bug)
+            self.assert_('regression-retracer' in b.keywords)
+
+    unittest.main()

=== added file 'backends/packaging_pisi.py'
--- backends/packaging_pisi.py	1970-01-01 00:00:00 +0000
+++ backends/packaging_pisi.py	2009-06-04 21:39:14 +0000
@@ -0,0 +1,259 @@
+'''Class that abstracts and encapsulates all packaging system queries that the
+various parts of apport need.
+
+Copyright (C) 2007 Canonical Ltd.
+Author: Martin Pitt <martin.pitt@ubuntu.com>
+
+This program is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2 of the License, or (at your
+option) any later version.  See http://www.gnu.org/copyleft/gpl.html for
+the full text of the license.
+'''
+
+import os
+import sys
+sys.path.insert(0, '/home/seed/src/gsoc/pisi/')
+sys.path.insert(1, '/home/seed/src/gsoc/piksemel/build/lib.linux-i686-2.6/')
+import pisi
+
+
+class PiSiPackageInfo:
+    def __init__(self):
+        self.configuration = '/etc/apport.conf'
+        self.installdb = pisi.db.installdb.InstallDB()
+        self.packagedb = pisi.db.packagedb.PackageDB()
+
+    def get_version(self, package):
+        '''Return the installed version of a package.
+
+        Throw ValueError if package does not exist.
+        '''
+        if not self.installdb.has_package(package):
+            raise ValueError, "Unable to find package '%s'" % package
+        pkg = self.installdb.get_package(package)
+        #return pisi.util.package_name(package, pkg.version, pkg.release,
+        #                              False, False)
+        return '%s-%s-%s' % (pkg.version, pkg.release, pkg.build)
+
+    def get_available_version(self, package):
+        '''Return the latest available version of a package.
+
+        Throw ValueError if package does not exist.
+        '''
+        if not self.packagedb.has_package(package):
+            raise ValueError, "Unable to find package '%s'" % package
+        pkg = self.packagedb.get_package(package)
+        #return pisi.util.package_name(package, pkg.version, pkg.release, False,
+        #                              False)
+        return '%s-%s-%s' % (pkg.version, pkg.release, pkg.build)
+
+    def get_dependencies(self, package):
+        '''Return a list of packages a package depends on.'''
+        pkg = self.packagedb.get_package(package)
+        return pkg.runtimeDependencies()
+
+    def get_source(self, package):
+        '''Return the source package name for a package.
+
+        Throw ValueError if package does not exist.
+        '''
+        #FIXME: is this correct? I'm assuming sources are contained on .pisi
+        if not self.packagedb.has_package(package):
+            raise ValueError, "Unable to find package '%s'" % package
+        pkg = self.packagedb.get_package(package)
+        return pkg.name
+
+
+    def is_distro_package(self, package):
+        '''Check package origin.
+
+        Return True if the package is a genuine distro package, or False if it
+        comes from a third-party source.
+
+        Throw ValueError if package does not exist.
+        '''
+        self.get_version(package)
+        #TODO: implement me!
+        return True
+
+    def get_architecture(self, package):
+        '''Return the architecture of a package.
+
+        This might differ on multiarch architectures (e. g.  an i386 Firefox
+        package on a x86_64 system)
+        '''
+        #TODO: check if this is always true
+        return 'x86'
+
+    def get_files(self, package):
+        '''Return list of files shipped by a package.
+
+        Throw ValueError if package does not exist.
+        '''
+        try:
+            return self.installdb.get_files(package).list
+        except:
+            raise ValueError, "Unable to find package '%s'" % package
+
+    def get_modified_files(self, package):
+        '''Return list of all modified files of a package.'''
+        files = self.installdb.get_files(package)
+        modified_files = []
+        for f in files.list:
+            if not f.hash:
+                continue
+            if os.path.lexists('/%s' % f.path):
+                if pisi.operations.check.file_corrupted(f):
+                    modified_files.append(f.path)
+        return modified_files
+
+    def get_file_package(self, file, uninstalled=False, map_cachedir=None):
+        '''Return the package a file belongs to.
+
+        Return None if the file is not shipped by any package.
+
+        If uninstalled is True, this will also find files of uninstalled
+        packages; this is very expensive, though, and needs network access and
+        lots of CPU and I/O resources. In this case, map_cachedir can be set to
+        an existing directory which will be used to permanently store the
+        downloaded maps. If it is not set, a temporary directory will be used.
+        '''
+        #TODO: implement the uninstalled flag
+        if not uninstalled:
+            package, files = pisi.api.search_file(file)
+            return package
+        else:
+            repodb = pisi.db.repodb.RepoDB()
+            for repo in repodb.list_repos():
+                for pkg in self.packagedb.list_packages():
+                    metadata = pkg.get_metadata()
+                    xml = open(metadata).read()
+                    paths = re.compile('<Path>(.*?%s.*?)</Path>' %
+                                       re.escape(file), re.I).findall(xml)
+                    if paths is not None:
+                        return pkg.name
+
+
+    def get_system_architecture(self):
+        '''Return the architecture of the system.
+
+        This should use the notation of the particular distribution.
+        '''
+        #TODO: check if this is always true
+        return 'x86'
+
+    def set_mirror(self, url):
+        '''Explicitly set a distribution mirror URL.
+
+        This might be called for operations that need to fetch distribution
+        files/packages from the network.
+
+        By default, the mirror will be read from the system configuration
+        files.
+        '''
+        #TODO: wtf?
+        raise NotImplementedError, 'this method must be implemented by a concrete subclass'
+
+    def get_source_tree(self, srcpackage, dir, version=None):
+        '''Download a source package and unpack it into dir..
+
+        dir should exist and be empty.
+
+        This also has to care about applying patches etc., so that dir will
+        eventually contain the actually compiled source.
+
+        If version is given, this particular version will be retrieved.
+        Otherwise this will fetch the latest available version.
+
+        Return the directory that contains the actual source root directory
+        (which might be a subdirectory of dir). Return None if the source is
+        not available.
+        '''
+        opt = pisi.config.Options()
+        opt.output_dir = dir
+        pisi.api.set_options(opt)
+        bld = pisi.operations.build.Builder.from_name(srcpackage)
+
+        # from Builder.build()
+        bld.compile_action_script()
+        bld.compile_comar_script()
+        bld.check_build_dependencies()
+        bld.fetch_component()
+        bld.fetch_source_archive()
+        bld.unpack_source_archive()
+
+        return bld.pkg_work_dir()
+
+    def compare_versions(self, ver1, ver2):
+        '''Compare two package versions.
+
+        Return -1 for ver < ver2, 0 for ver1 == ver2, and 1 for ver1 > ver2.
+        '''
+        v1 = pisi.version.Version(ver1)
+        v2 = pisi.version.Version(ver2)
+        if v1 < v2:
+            return -1
+        elif v1 > v2:
+            return 1
+        else:
+            return 0
+
+    def enabled(self):
+        '''Return whether Apport should generate crash reports.
+
+        Signal crashes are controlled by /proc/sys/kernel/core_pattern, but
+        some init script needs to set that value based on a configuration file.
+        This also determines whether Apport generates reports for Python,
+        package, or kernel crashes.
+
+        Implementations should parse the configuration file which controls
+        Apport (such as /etc/default/apport in Debian/Ubuntu).
+        '''
+        # Ripped off from apt-dpkg backend
+        try:
+            conf = open(self.configuration).read()
+        except IOError:
+            # if the file does not exist, assume it's enabled
+            return True
+
+        return re.search('^\s*enabled\s*=\s*0\s*$', conf, re.M) is None
+
+    def get_kernel_package(self):
+        '''Return the actual Linux kernel package name.
+
+        This is used when the user reports a bug against the "linux" package.
+        '''
+        return 'kernel'
+
+    def install_retracing_packages(self, report, verbosity=0,
+            unpack_only=False, no_pkg=False, extra_packages=[]):
+        '''Install packages which are required to retrace a report.
+
+        If package installation fails (e. g. because the user does not have root
+        privileges), the list of required packages is printed out instead.
+
+        If unpack_only is True, packages are only temporarily unpacked and
+        purged again after retrace, instead of permanently and fully installed.
+        If no_pkg is True, the package manager is not used at all, but the
+        binary packages are just unpacked with low-level tools; this speeds up
+        operations in fakechroots, but makes it impossible to cleanly remove
+        the package, so only use that in apport-chroot.
+
+        Return a tuple (list of installed packages, string with outdated packages).
+        '''
+        raise NotImplementedError, 'this method must be implemented by a concrete subclass'
+
+    def remove_packages(self, packages, verbosity=0):
+        '''Remove packages.
+
+        This is called after install_retracing_packages() to clean up again
+        afterwards. packages is a list of package names.
+        '''
+        pisi.api.remove(packages)
+
+    def package_name_glob(self, glob):
+        '''Return known package names which match given glob.'''
+        return pisi.api.search_package(glob)
+
+impl = PiSiPackageInfo()

